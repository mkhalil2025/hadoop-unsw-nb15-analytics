services:
  # PostgreSQL Metastore for Hive
  postgres:
    image: postgres:13
    container_name: postgres-metastore
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive123
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - hadoop-network
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Hadoop Namenode
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    hostname: namenode
    environment:
      CLUSTER_NAME: hadoop-cluster
    env_file:
      - .env
      - hadoop.env
    volumes:
      - namenode_data:/hadoop/dfs/name
      - ./config:/opt/hadoop-3.2.1/etc/hadoop
      - ./data:/opt/hadoop/data
    ports:
      - "9870:9870"  # Namenode Web UI
      - "8020:8020"  # Namenode RPC
    networks:
      - hadoop-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9870 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Hadoop Datanode
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    hostname: datanode
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - .env
      - hadoop.env
    volumes:
      - datanode_data:/hadoop/dfs/data
      - ./config:/opt/hadoop-3.2.1/etc/hadoop
      - ./data:/opt/hadoop/data
    ports:
      - "9864:9864"  # Datanode Web UI
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy

  # YARN ResourceManager
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    hostname: resourcemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - .env
      - hadoop.env
    volumes:
      - ./config:/opt/hadoop-3.2.1/etc/hadoop
    ports:
      - "8088:8088"  # ResourceManager Web UI
      - "8030:8030"  # ResourceManager Scheduler
      - "8031:8031"  # ResourceManager Tracker
      - "8032:8032"  # ResourceManager Applications
      - "8033:8033"  # ResourceManager Admin
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy

  # YARN NodeManager
  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    hostname: nodemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - .env
      - hadoop.env
    volumes:
      - ./config:/opt/hadoop-3.2.1/etc/hadoop
      - nodemanager_data:/opt/hadoop/logs
    ports:
      - "8042:8042"  # NodeManager Web UI
    networks:
      - hadoop-network
    depends_on:
      - resourcemanager

  # Hive Server2
  hiveserver2:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hiveserver2
    hostname: hiveserver2
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://postgres:5432/metastore"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionDriverName: "org.postgresql.Driver"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionUserName: "hive"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionPassword: "hive123"
      HIVE_CORE_CONF_datanucleus_autoCreateSchema: "false"
      HIVE_SITE_CONF_hive_metastore_uris: "thrift://hivemetastore:9083"
      HIVE_SITE_CONF_hive_metastore_schema_verification: "true"
      HIVE_SITE_CONF_hive_server2_enable_doAs: "false"
      HIVE_SITE_CONF_hive_server2_thrift_bind_host: "0.0.0.0"
      SERVICE_PRECONDITION: "hivemetastore:9083"
    env_file:
      - .env
      - hadoop.env
    volumes:
      - ./hive:/opt/hive/scripts
      - ./config:/opt/hadoop-3.2.1/etc/hadoop
      - ./output:/opt/hive/output
      - ./scripts:/opt/scripts
    ports:
      - "10000:10000"  # HiveServer2 Thrift
      - "10002:10002"  # HiveServer2 Web UI
    networks:
      - hadoop-network
    depends_on:
      hivemetastore:
        condition: service_healthy
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "netstat -ln | grep 10000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    restart: on-failure

  # Hive Metastore
  hivemetastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hivemetastore
    hostname: hivemetastore
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 postgres:5432"
      HADOOP_HOME: "/opt/hadoop-2.7.4"
      HADOOP_PREFIX: "/opt/hadoop-2.7.4"
      HADOOP_CONF_DIR: "/opt/hadoop-2.7.4/etc/hadoop"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://postgres:5432/metastore"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionDriverName: "org.postgresql.Driver"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionUserName: "hive"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionPassword: "hive123"
      HIVE_CORE_CONF_datanucleus_autoCreateSchema: "true"
      HIVE_CORE_CONF_datanucleus_fixedDatastore: "false"
      HIVE_CORE_CONF_datanucleus_schema_autoCreateAll: "true"
      HIVE_CORE_CONF_datanucleus_schema_autoCreateTables: "true"
      HIVE_CORE_CONF_datanucleus_schema_autoCreateColumns: "true"
      HIVE_CORE_CONF_datanucleus_schema_autoCreateConstraints: "true"
      HIVE_SITE_CONF_hive_metastore_schema_verification: "false"
      HIVE_SITE_CONF_hive_metastore_schema_verification_record_version: "false"
      HIVE_SITE_CONF_datanucleus_autoCreateSchema: "true"
      HIVE_SITE_CONF_datanucleus_schema_autoCreateTables: "true"
    volumes:
      - ./scripts:/opt/scripts
    ports:
      - "9083:9083"  # Metastore Thrift
    networks:
      - hadoop-network
    depends_on:
      postgres:
        condition: service_healthy
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "netstat -ln | grep 9083 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: on-failure
    command: /opt/hive/bin/hive --service metastore

  # Jupyter Notebook for Python Analytics
  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter-analytics
    hostname: jupyter
    environment:
      JUPYTER_ENABLE_LAB: "yes"
      GRANT_SUDO: "yes"
    user: root
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./python:/home/jovyan/python
      - ./data:/home/jovyan/data
      - ./output:/home/jovyan/output
      - ./hive:/home/jovyan/hive
    ports:
      - "8888:8888"  # Jupyter Lab
    networks:
      - hadoop-network
    command: >
      bash -c "
        pip install --upgrade pip &&
        pip install pyhive thrift sasl thrift_sasl hdfs3 &&
        pip install matplotlib seaborn scikit-learn pandas numpy plotly &&
        pip install PyHive[hive] sqlalchemy &&
        pip install imbalanced-learn xgboost lightgbm &&
        pip install tensorflow keras torch torchvision &&
        pip install networkx pyvis dash streamlit &&
        pip install psycopg2-binary pymongo cassandra-driver &&
        pip install apache-airflow great-expectations evidently &&
        pip install shap lime yellowbrick &&
        start-notebook.sh --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.allow_root=True
      "

volumes:
  namenode_data:
  datanode_data:
  nodemanager_data:
  postgres_data:

networks:
  hadoop-network:
    driver: bridge